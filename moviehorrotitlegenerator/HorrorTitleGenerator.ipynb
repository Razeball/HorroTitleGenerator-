{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b38883f-ee53-4a37-af48-4fc2fc95a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import random\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55cd248c-9be6-4ec8-8c3a-70e754033e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"horror_movies.csv\")\n",
    "titles = []\n",
    "for title in df[\"title\"]:\n",
    "    cleaned_title = title.lower().strip()\n",
    "    cleaned_title = re.sub(r'[0-9]', '', cleaned_title)\n",
    "    cleaned_title = re.sub(r'[^\\w\\s]', '', cleaned_title)\n",
    "    cleaned_title = re.sub(r'\\s+', ' ', cleaned_title)\n",
    "    titles.append(cleaned_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a675e0-2974-4700-9ba1-012eb4ec4900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_vectorizer = TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    ")\n",
    "global_vectorizer.adapt(titles)\n",
    "vocab = global_vectorizer.get_vocabulary()\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180ee481-3b34-4f81-afa8-ac8532d5a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_titles = []\n",
    "for title in titles:\n",
    "    tokens = global_vectorizer([title]).numpy()[0]\n",
    "    words = [vocab[i] for i in tokens if i != 0]\n",
    "    if len(words) > 2:\n",
    "        filtered_titles.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14504ca-9061-4772-8b31-da4213eaffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sequences = []\n",
    "for words in filtered_titles:\n",
    "    indices = [vocab.index(w) for w in words]\n",
    "    for i in range(1, len(indices)):\n",
    "        n = indices[:i+1]\n",
    "        data_sequences.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce0c650-1618-40c4-b823-e97a1d73cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in data_sequences])\n",
    "data_sequences = pad_sequences(data_sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48280144-c3ce-4277-a830-2e4f2fcaa071",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_sequences[:, :-1]\n",
    "y = data_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7705131e-cb1b-40d7-8ee7-b0d55051f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 128, input_length=max_len-1),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27e4c99-7f3e-408a-bbf0-14afdd44a9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0dc88a-54a4-4265-868c-58dde421fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34ab04a3-0f1e-41c2-9b3e-e40abd11e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=5, min_lr=1e-6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afbbb155-29cd-4a4b-986a-4fc11bf0ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Said\\anaconda3\\envs\\tf310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "2376/2376 [==============================] - 41s 16ms/step - loss: 7.2499 - accuracy: 0.1087 - val_loss: 7.4226 - val_accuracy: 0.1075 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2376/2376 [==============================] - 39s 16ms/step - loss: 6.6153 - accuracy: 0.1481 - val_loss: 7.5264 - val_accuracy: 0.1176 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2376/2376 [==============================] - 39s 16ms/step - loss: 6.3237 - accuracy: 0.1595 - val_loss: 7.7019 - val_accuracy: 0.1197 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2376/2376 [==============================] - 39s 16ms/step - loss: 6.1341 - accuracy: 0.1643 - val_loss: 7.7976 - val_accuracy: 0.1199 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2376/2376 [==============================] - 39s 16ms/step - loss: 5.9983 - accuracy: 0.1660 - val_loss: 7.9562 - val_accuracy: 0.1194 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2374/2376 [============================>.] - ETA: 0s - loss: 5.8755 - accuracy: 0.1678 \n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "2376/2376 [==============================] - 39s 16ms/step - loss: 5.8756 - accuracy: 0.1677 - val_loss: 8.0683 - val_accuracy: 0.1239 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2376/2376 [==============================] - 40s 17ms/step - loss: 5.7376 - accuracy: 0.1713 - val_loss: 8.1517 - val_accuracy: 0.1227 - lr: 7.0000e-04\n",
      "Epoch 8/50\n",
      "2376/2376 [==============================] - 40s 17ms/step - loss: 5.6366 - accuracy: 0.1733 - val_loss: 8.2148 - val_accuracy: 0.1249 - lr: 7.0000e-04\n",
      "Epoch 9/50\n",
      "2376/2376 [==============================] - 40s 17ms/step - loss: 5.5404 - accuracy: 0.1769 - val_loss: 8.3524 - val_accuracy: 0.1224 - lr: 7.0000e-04\n",
      "Epoch 10/50\n",
      "2376/2376 [==============================] - 39s 17ms/step - loss: 5.4454 - accuracy: 0.1798 - val_loss: 8.3445 - val_accuracy: 0.1320 - lr: 7.0000e-04\n",
      "Epoch 11/50\n",
      "Restoring model weights from the end of the best epoch: 1.s: 5.3615 - accuracy: 0.1824  \n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "2376/2376 [==============================] - 40s 17ms/step - loss: 5.3613 - accuracy: 0.1824 - val_loss: 8.4645 - val_accuracy: 0.1343 - lr: 7.0000e-04\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=50, batch_size=16, validation_split=0.15, callbacks=[early_stopping, reduce_lr], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87d7ce8-78c9-4513-bd6a-27a7f681abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temperature(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-8) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(preds), p=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23dc098-32f4-4f78-9de5-0a6eed838f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_title(seed_text=\"\", min_length=3, max_length=8, temperature=0.8):\n",
    "    if not seed_text:\n",
    "        seed_words = [\"night\", \"dark\", \"blood\", \"evil\", \"dead\", \"horror\", \"the\"]\n",
    "        seed_text = random.choice(seed_words)\n",
    "    generated_words = seed_text.split()\n",
    "    for _ in range(max_length - len(generated_words)):\n",
    "        token_list = [vocab.index(w) if w in vocab else 1 for w in generated_words] \n",
    "        token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted_word_index = sample_with_temperature(predicted[0], temperature)\n",
    "        output_word = vocab[predicted_word_index] if predicted_word_index < len(vocab) else ''\n",
    "        if (not output_word) or (output_word in generated_words) or (output_word == '<OOV>'):\n",
    "            break\n",
    "        generated_words.append(output_word)\n",
    "        if len(generated_words) >= min_length and random.random() > 0.7:\n",
    "            break\n",
    "    return \" \".join(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb1ac08e-9b5e-4369-bb8c-9001bfdbfa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_titles(num_titles=5, temperature=0.8):\n",
    "    titles = []\n",
    "    for _ in range(num_titles):\n",
    "        title = generate_title(temperature=temperature)\n",
    "        if len(title.split()) >= 2:\n",
    "            titles.append(title)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "537c438b-0685-40bb-a6d7-246b3d952415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. dead love treat\n",
      "2. blood of the house\n",
      "3. blood of the dead\n",
      "4. dead of man the\n",
      "5. blood the for us of\n",
      "6. blood of the\n",
      "7. dark moonlight of\n",
      "8. night of the clown\n",
      "9. evil of the\n",
      "10. blood white the\n"
     ]
    }
   ],
   "source": [
    "generated_titles = generate_multiple_titles(10, temperature=0.7)\n",
    "for i, title in enumerate(generated_titles, 1):\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1dce1a-9272-41ba-b9d8-8efcd71ece12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF 2.13 CPU)",
   "language": "python",
   "name": "tf310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
